---
title: "WildCard Results"
author: "Jeffrey M. Pisklak"
date: "`r Sys.Date()`"
output: html_document
bibliography: references.bib
csl: apa-with-abstract.csl

nocite: |
  @R
---
<!-- https://www.w3schools.com/tags/tag_details.asp -->
<style>
details > summary {
  padding: 4px;
  cursor: pointer;
  font-size: 2em;
}
</style>

<br>

```{r setup, include = FALSE}
options(pillar.print_max = Inf)
if(!require(knitr)){install.packages('knitr')}
if(!require(kableExtra)){install.packages('kableExtra')}
library(knitr)
library(kableExtra)

#Directory
#opts_knit$set(root.dir = dirname(getwd())) #Rendering from this .Rmd file.
opts_knit$set(root.dir = main_dir) #Rendering from Gen_Rmd_Doc
```

```{r include = FALSE}
if (!file.exists('Data/wc_full_data.csv')) {
  source('R Scripts/data_merge_filter.R')
  }
```



# **Participant Stats**

<!-- Pre-catch Exclusion -->

```{r echo = FALSE, message = FALSE, warning = FALSE}
source('R Scripts/subj_stats.R')
```

<details>
  <summary>
  Pre-catch exclusion
  </summary>
  
N = `r N`
  
```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(pre_catch, 'html', digits = 3) %>%
  kable_classic(full_width = T, position = "center", html_font = "Arial")
```

</details> 

<!-- Post-catch Exclusion -->

<details>
  <summary>
  Post-catch exclusion
  </summary>

N = `r (N - catch_n)`

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(post_catch, 'html', digits = 3) %>%
  kable_classic(full_width = T, position = "center", html_font = "Arial")
```

<br>

<h4>Condition totals:</h4>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(demo_info_f %>%
  group_by(condition) %>%
  summarise(n = length(ID),
            age_mean = mean(age, na.rm = TRUE),
            age_sd = sd(age, na.rm = TRUE),
            age_median = median(age, na.rm = TRUE),
            age_IQR = IQR(age, na.rm = TRUE),
            dur_minutes_mean = mean(exp_dur/60, na.rm = TRUE),
            dur_minutes_median = median(exp_dur/60, na.rm = TRUE)),
  'html', digits = 3) %>%
  kable_classic(full_width = T, position = "left", html_font = "Arial")
```

</details> 

<!-- Other Notes -->

<details>
  <summary>
  Notes
  </summary>

- Total number of catch trial exclusions = `r catch_n`.

- Some participants reported a program crash during the memory phase. Their data is included in the numbers above. For reference:

  - `r nrow(fo_comp)` crashed in the first-outcome judgment.
  - `r nrow(fj_comp)` crashed in the frequency judgment.

</details> 

<br>

---

<br>




# **Catch Trials**

<!-- Catch Trial Plots -->

<details>
  <summary>
  Plot - Session means
  </summary>
  
<br>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.height = 5.6}
#source('R Scripts/catch_trials.R')
plt_catch
```

Errorbars = 95% CI

</details> 

<br>

---

<br>




# **Risk Preference Trials**

<details>
  <summary>
  Details and complications with the risky-choice data
  </summary>

**Data is lumpy:**

- There is not a lot of distinction among the measured choice proportions.  All of the measurements can be categorized in to just 13 bins (see table below). For future studies, it might be worth adding additional testing trials to obtain a more continuous set of measurements. 

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 19, fig.height = 7}
source('R Scripts/risky_trials_analysis.R')

bins <- data.frame(table(subject_res$cp))
bins$Var1 <- as.numeric(as.character(bins$Var1))
bins$Freq <- as.integer(bins$Freq)
colnames(bins) <- c('CP', 'Frequency')

kable(t(bins), 'html', digits = 2) %>%
  kable_classic(full_width = F, position = "center", html_font = "Arial")

```

**High-value risky choices are bimodal**

- For the high-value choice, most values are either 0 or 1 (see histograms below). This is actually a important aspect of the data that (probably?) hasn't been noticed/discussed in past extreme-outcome papers.  Looking at the means, the high-value choices appear to be around indifference ($\approx 0.46$), but the histograms show that this is an artifact of the aggregation.

- At the level of the individual, most participants either completely prefer the fixed alternative or completely prefer the risky alternative with some in between. Statistically, it's not clear what the best way to handle this fact given the between- and within- subject manipulations. In any case, it's probably worth pointing out to the readers that the mean proportion for the high-value choices is not really describing the individual data all that accurately. **i.e., The population is indifferent; however, the individuals are not (generally speaking).**

**Low-value choices are heavily skewed**

- By and large participants are only choosing the fixed option, creating very heavy skew.  Consequently, people are much more risk-averse in the low-value context than the means would suggest they are (compare the low value mean vs median choice proportions in the summary stat table).

**Classic ANOVA is probably inadequate**

- A conventional ANOVA does not model this data very well. Note the non-normal residuals in the Q-Q plot below (from the ANOVA run on the differences). The pre-registration document calls for three separate ANOVAs, which are provided below. However, given the residuals, it's probably not wise to rely on a conventional ANOVA methodology. i.e., one based around ordinary least-squares (OLS). Consequently, an ANOVA using generalized least-squares (GLS) fit by maximum likelihood has been applied.

- A perhaps(?) slightly better (i.e., more robust) alternative (that is still consistent with your pre-registration) would be to conduct three bootstrapped heteroscedastic one-way ANOVAs for trimmed means. Though, that analysis isn't shown here because it doesn't impact the conclusions and doesn't allow for planned contrasts. Further, trimming is a foreign concept for many that is likely to perturb reviewers unfamiliar with it - though, the averages for the low-value choices would probably be more accurate. 

- In addition to the three one-way ANOVAs, a 2x3 ANOVA using a linear mixed effects (LME) models fit by maximum likelihood has been run - because it seems like the more elegant way to approach this particular experimental design which has both between- and within- subjects factors.

- Having said all that, no matter what approach you take (OLS, GLS, trimmed-bootstraps, or LME), you will end up drawing the same conclusions. Though, the 2x3 LME approach seems the most elegant way of arriving at them and will probably read the best in the manuscript.

<br>

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 19, fig.height = 7}
#Histograms
hist <- ggplot(subject_res, aes(x = cp)) +
  geom_histogram(aes(fill = risky_choice),
                 colour = 'black',
                 bins = 13) +
  facet_grid(risky_choice ~ condition) +
  scale_x_continuous(breaks = seq(0, 1, 0.5)) +
  theme_custom() +
  theme(axis.text = element_text(colour = 'black', size = 16),
        axis.title = element_text(colour = 'black', size = 16),
        strip.text=element_text(size = 20, colour = 'black',
                              margin = margin(1,0,1,0, "cm")),
        panel.spacing = unit(1.25, "lines"))

#QQ plot of difference model
qq <- ggplot(mapping = aes(sample = diff_mod$residuals)) +
  stat_qq() +
  stat_qq_line() +
  xlab('Theoretical Quantiles') + ylab('Residuals') +
  theme_custom() +
  theme(axis.text = element_text(colour = 'black', size = 16),
        axis.title = element_text(colour = 'black', size = 16),
        strip.text=element_text(size = 14, colour = 'black',
                              margin = margin(1,0,1,0, "cm")),
        panel.spacing = unit(1.25, "lines"))

hist + plot_spacer() + qq + plot_layout(widths = c(5, 1, 5))
```

</details> 


<details>
  <summary>
  Summary statistics
  </summary>

<br>

<h3> Summary statistics for risky choice trials </h3>

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 5, fig.height = 4}

s <- subject_res %>%
  group_by(condition, risky_choice) %>%
  summarise(
    n = length(cp),
    mean = mean(cp),
    sd = sd(cp),
    median = median(cp),
    IQR = IQR(cp)
    )

kable(s, 'html', digits = 3) %>%
  kable_classic(full_width = T, position = "center", html_font = "Arial") %>%
  column_spec(c(4, 6), bold = T)
```

<br>

</details> 


<details>
  <summary>
  Plot - Barplot of means
  </summary>

Note: 

- Errorbars are 95% CIs.
- Bootstrapping produces no appreciable difference in the obtained means or errorbars.

<br>

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 15}
#source('R Scripts/risky_trials_analysis.R')
plts_risky
```

</details> 

<details>
  <summary>
  Plot - Violin plot
  </summary>
  
Given its general weirdness, it seems unlikely you would include this in the manuscript, but its a much more accurate depiction of your data than either of the barplots are.

How to read:

- The fatter the shape, the more dense the values are at that location on the y-axis.
- The point range (circle with vertical line) shows the mean and 95% CI.
- The thick horizontal line shows the median.
- The small transparent points are individual scores with some random horizontal noise added to prevent overplotting. Notice the data clumps into 13 spots.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 5.6}
#source('R Scripts/risky_trials_analysis.R')
plt_risky_violin
```

</details> 

<details>
  <summary>
  Plot - EO difference by block
  </summary>
  
  <br>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 5.6}
#source('R Scripts/risky_trials_analysis.R')
plt_risky_diff_blks
```  
  
</details>

<details>
  <summary>
  Plot - High and low risk preference by block
  </summary>
  
  <br>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 7}
#source('R Scripts/risky_trials_analysis.R')
plt_risky_std_blks
```  
  
</details>


<!-- One-Way ANOVA on Difference (High - Low) -->

<details>
  <summary>
  One-way ANOVA on difference / EO effect (high - low)
  </summary>
  
<h3>ANOVA Table</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(anova_diff, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note: 

- ANOVA was run using generalized least-squares fit by maximum likelihood.
- $R^2_N$ is Nagelkerke's (also known as Cragg and Uhler's) pseudo $R^2$ [@Nagelkerke]. It isn't interpreted in exactly the same way as a $R^2$ based on ordinary least-squares regression, but it is bounded by 0 and 1 and higher values indicate a better model fit.

<br>

<!-- Planned Contrasts -->

<h3>Planned contrasts</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(pc_diff, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- E1_v_E2NE = *Extreme First* vs. combined effect of *Extreme Last* and *No Extreme*
- E2_v_NE = *Extreme Last* vs. *No Extreme*

<br>

<!-- Pairwise Comparisons -->

<h3>Pairwise comparisons: Post-hoc comparisons for heteroscedastic means</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(ph_diff, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- $\hat{\Psi}$ is the difference between condition means.
- These post-hoc tests don't assume equal variance, but do assume normality. Trimming can easily be added to make it more robust to non-normality.
- The Hochberg correction [@hochberg1988] was applied to protect family-wise error rate, but others like Holm's or Benjamini & Hochberg's could be used instead.

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
f <- round(anova_diff$`F-value`[2], 2)
df <- round(anova_diff$numDF[2:3])
p <- round(anova_diff$`p-value`[2], 3)
R2 <- round(anova_diff$pseudo_R2[2], 2)

b = round(pc_diff$Value[c(2, 3)], 3)
df_2 = round(pc_diff$DF[c(2, 3)])
t = round(pc_diff$`t-value`[c(2, 3)], 2)
p_2 = round(pc_diff$`p-value`[c(2, 3)], 3)
r = round(pc_diff$r_effect[c(2, 3)], 3)
```


**Effect of condition:**

$F(`r df[1]`, `r df[2]`) = `r f`, p = `r p`, R^2_N = `r R2`$ 

- There is no significant effect.

<br>

**Planned comparisons:**

Extreme First vs. (Extreme Last & No Extreme)

$t(`r df_2[1]`) = `r t[1]`$, $p = `r p_2[1]`$, $r = `r r[1]`$

- The *Extreme First* condition is significantly different from the combination of the other two conditions. Note that the effect is small and may be of little practical value.

<br>

Extreme Last vs. No Extreme

$t(`r df_2[2]`) = `r t[2]`$, $p = `r p_2[2]`$, $r = `r r[2]`$

- The *Extreme Last* and *No Extreme* conditions do not significantly differ. 

<br>

</details>

<!-- One-Way ANOVA on High Value Choices -->

<details>
  <summary>
  One-way ANOVA on high-value choices
  </summary>
  
<h3>ANOVA table</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(anova_hv, 'html', digits = 4) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note: 

- ANOVA was run using generalized least-squares fit by maximum likelihood.
- $R^2_N$ is Nagelkerke's (also known as Cragg and Uhler's) pseudo $R^2$ [@Nagelkerke]. It isn't interpreted in exactly the same way as a $R^2$ based on ordinary least-squares regression, but it is bounded by 0 and 1 and higher values indicate a better model fit.

<br>

<!-- Planned Contrasts -->

<h3>Planned contrasts</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(pc_hv, 'html', digits = 4) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- E1_v_E2NE = *Extreme First* vs. combined effect of *Extreme Last* and *No Extreme*
- E2_v_NE = *Extreme Last* vs. *No Extreme*

<br>

<!-- Pairwise Comparisons -->

<h3>Pairwise comparisons: Post-hoc comparisons for heteroscedastic means</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(ph_hv, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- $\hat{\Psi}$ is the difference between condition means.
- These post-hoc tests don't assume equal variance, but do assume normality. Trimming can easily be added to make it more robust.
- The Hochberg correction [@hochberg1988] was applied to protect family-wise error rate, but others like Holm's or Benjamini & Hochberg's could be used instead.

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
f <- round(anova_hv$`F-value`[2], 3)
df <- round(anova_hv$numDF[2:3])
p <- round(anova_hv$`p-value`[2], 3)
R2 <- round(anova_hv$pseudo_R2[2], 3)

b = round(pc_hv$Value[c(2, 3)], 3)
df_2 = round(pc_hv$DF[c(2, 3)])
t = round(pc_hv$`t-value`[c(2, 3)], 2)
p_2 = round(pc_hv$`p-value`[c(2, 3)], 3)
r = round(pc_hv$r_effect[c(2, 3)], 3)
```


**Effect of of condition:**

$F(`r df[1]`, `r df[2]`) = `r f`, p = `r p`, R^2_N = `r R2`$ 

- There is no significant effect.

<br>

**Planned comparisons:**

Extreme First vs. (Extreme Last & No Extreme)

$t(`r df_2[1]`) = `r t[1]`$, $p = `r p_2[1]`$, $r = `r r[1]`$

- The *Extreme First* condition is not significantly different from the combination of the other two conditions.

<br>

Extreme Last vs. No Extreme

$t(`r df_2[2]`) = `r t[2]`$, $p = `r p_2[2]`$, $r = `r r[2]`$

- The *Extreme Last* and *No Extreme* conditions do not significantly differ. 

<br>

</details>


<!-- One-Way ANOVA on Low Value Choices -->

<details>
  <summary>
  One-way ANOVA on low-value choices
  </summary>
  
<h3>ANOVA Table</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(anova_lv, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note: 

- ANOVA was run using generalized least-squares fit by maximum likelihood.
- $R^2_N$ is Nagelkerke's (also known as Cragg and Uhler's) pseudo $R^2$ [@Nagelkerke]. It isn't interpreted in exactly the same way as a $R^2$ based on ordinary least-squares regression, but it is bounded by 0 and 1 and higher values indicate a better model fit.

<br>

<!-- Planned Contrasts -->

<h3>Planned contrasts</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(pc_lv, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- E1_v_E2NE = *Extreme First* vs. combined effect of *Extreme Last* and *No Extreme*
- E2_v_NE = *Extreme Last* vs. *No Extreme*

<br>

<!-- Pairwise Comparisons -->

<h3>Pairwise comparisons: Post-hoc comparisons for heteroscedastic means</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(ph_lv, 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

Note:

- $\hat{\Psi}$ is the difference between condition means.
- These post-hoc tests don't assume equal variance, but do assume normality. Trimming can easily be added to make it more robust.
- The Hochberg correction [@hochberg1988] was applied to protect family-wise error rate, but others like Holm's or Benjamini & Hochberg's could be used instead.

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
f <- round(anova_lv$`F-value`[2], 2)
df <- round(anova_lv$numDF[2:3])
p <- round(anova_lv$`p-value`[2], 3)
R2 <- round(anova_lv$pseudo_R2[2], 2)

b = round(pc_lv$Value[c(2, 3)], 3)
df_2 = round(pc_lv$DF[c(2, 3)])
t = round(pc_lv$`t-value`[c(2, 3)], 2)
p_2 = round(pc_lv$`p-value`[c(2, 3)], 3)
r = round(pc_lv$r_effect[c(2, 3)], 2)
```


**Effect of of condition:**

$F(`r df[1]`, `r df[2]`) = `r f`, p = `r p`, R^2_N = `r R2`$ 

- There is a significant effect.

<br>

**Planned Comparisons:**

Extreme First vs. (Extreme Last & No Extreme)

$t(`r df_2[1]`) = `r t[1]`$, $p = `r p_2[1]`$, $r = `r r[1]`$

- The *Extreme First* condition is significantly different from the combination of the other two conditions.

<br>

Extreme Last vs. No Extreme

$t(`r df_2[2]`) = `r t[2]`$, $p = `r p_2[2]`$, $r = `r r[2]`$

- The *Extreme Last* and *No Extreme* conditions do not significantly differ. 

<br>

</details>

<!-- 2x3 ANOVA using LME Models Fit by Maximum Likelihood -->

<details>
  <summary>
  2x3 ANOVA using linear mixed-effects models fit by maximum likelihood
  </summary>

<h3>ANOVA Table</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(aov_2x3[, -c(1)], 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

- base = intercept only (used as baseline and predicts overall mean ignoring other factors)
- cond_mod = effect of adding condition
- HL_mod = effect of adding context (i.e., High / Low choices)
- int_mod = interaction effect

<br>

<h3>Planned contrasts</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(round(pc, 3), 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

- E1_v_E2NE = *Extreme First* vs. combined effect of *Extreme Last* and *No Extreme*
- E2_v_NE = *Extreme Last* vs. *No Extreme*
- risky_choice1 = *High vs Low* (same test as row 3 in the ANOVA table)

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
df = aov_2x3$df[2:4] - aov_2x3$df[1:3]
chi = round(aov_2x3$L.Ratio[2:4], 2)
p = round(aov_2x3$`p-value`[2:4], 3)
R2 = round(aov_2x3$pseudo_R2[2:4], 2)
BF = format(round(aov_2x3$BF_10[2:4], 2), scientific = FALSE)

b = round(pc$Value[c(2, 3, 5, 6)], 3)
df_2 = round(pc$DF[c(2, 3, 5, 6)])
t = round(pc$`t-value`[c(2, 3, 5, 6)], 2)
p_2 = round(pc$`p-value`[c(2, 3, 5, 6)], 3)
r = round(pc$r_effect[c(2, 3, 5, 6)], 3)
```

**Main effect of of condition:**

$\chi^2 (`r df[1]`) = `r chi[1]`, p = `r p[1]`, R^2_N = `r R2[1]`, BF_{10} = `r BF[1]`$

- There is no main effect of condition.

<br>

**Main effect of of context (high vs low):**

$\chi^2 (`r df[2]`) = `r chi[2]`, p = `r p[2]`, R^2_N = `r R2[2]`, BF_{10} = `r BF[2]`$

- There is a main effect of context (high-value choices vs. low-value).

<br>

**Interaction:**

$\chi^2 (`r df[3]`) = `r chi[3]`, p = `r p[3]`, R^2_N = `r R2[3]`, BF_{10} = `r BF[3]`$

- There is no overall interaction.

<br>

**Planned comparisons:**

Given the lack of interaction and main effect of condition, it's debatable whether the extra step of interpreting the planned comparisons should be taken. However, since the planned comparisons test more refined *a priori* predictions, it seems like they might be more important than the main effects, which lack nuance.

<br>

Extreme First vs. (Extreme Last & No Extreme)

$t(`r df_2[1]`) = `r t[1]`$, $p = `r p_2[1]`$, $r = `r r[1]`$

- The *Extreme First* condition is significantly different from the combination of the other two conditions. Note that the effect is small and may be of little practical value.

<br>

Extreme Last vs. No Extreme

$t(`r df_2[2]`) = `r t[2]`$, $p = `r p_2[2]`$, $r = `r r[2]`$

- The *Extreme Last* and *No Extreme* conditions do not significantly differ. 

<br>

Extreme First vs. (Extreme Last & No Extreme) | Context (i.e., High vs. Low)

$t(`r df_2[3]`) = `r t[3]`$, $p = `r p_2[3]`$, $r = `r r[3]`$

- The first planned comparison significantly differs depending on context (i.e., the Extreme First condition only differs from the other two conditions for the low-value choices). Note that the effect is small and may be of little practical value.

<br>

Extreme Last vs. No Extreme | Context (i.e., High vs. Low)

$t(`r df_2[4]`) = `r t[4]`$, $p = `r p_2[4]`$, $r = `r r[4]`$

- The second planned comparison does not significantly differ depending on context (i.e., no interaction with context).

<br>


**Note:** 

- $p = 0$ should be reported as $p < .001$

- $R^2_N$ is Nagelkerke's (also known as Cragg and Uhler's) pseudo $R^2$ [@Nagelkerke]. It isn't interpreted in exactly the same way as a $R^2$ based on ordinary least-squares regression, but it is bounded by 0 and 1 and higher values indicate a better model fit.

- Bayes Factors are reported as Inverse Bayes Factors, this means larger values
indicate greater support for the effect. Anything less than 1 should be considered as contributing no evidence.

- If $BF_{10} > 150$, report that instead specifying the entire value.

</details>

<br>

---

<br>

# **First-Outcome Judgement**

<details>
  <summary>
  Details and complications of first-outcome judgement results
  </summary>

**Pre-registration document McNemar Tests:**

The pre-registration document states . . . 

- *The first-outcome memory tests will be analyzed with a sequence of three McNemar Tests.* **<u>Each test will compare two of the groups and</u> the proportion reporting the extreme option for the high- and low-value option.** *The target prediction of the Encoding Hypothesis is that the proportion of extreme outcomes reported first will be reliably lower in the Extreme First group. Ideally, we would run one test with all three groups (like an overall ANOVA), but as of the time of writing this pre-registration, we have not been able to identify the appropriate variation of a chi-squared test that would work for this scenario.*
  
Based on this, it seems that the plan was to use McNemar Tests for condition comparisons, doing so three times to compare each pair of conditions (E1 vs EL, E1 vs NE, EL vs NE), while also factoring in counts/proportions for the 20th and 80th extremes. It is not clear that there is a way to do that with this test.  You can do one McNemar Test for each condition (which is what has been done below), but you cannot compare across conditions, like is stated in the pre-registration document.

**Alternative to McNemar tests:**

An alternative method to obtain a comparison across conditions could be to run two standard Pearson's Chi-squared tests using a 3 x 2 contingency table for the the High and Low choices respectively, like so...

```{r echo = FALSE, message = FALSE, warning = FALSE}

df_h <- data.frame(
  `High Extreme` = c('a','c', 'e'),
  Other = c('b','d','f')
  )

df_l <- data.frame(
  `Low Extreme` = c('a','c', 'e'),
  Other = c('b','d','f')
  )

rownames(df_h) <- c('Extreme First', 'Extreme Last', 'No Extreme')
rownames(df_l) <- c('Extreme First', 'Extreme Last', 'No Extreme')

kable(df_h, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(df_l, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

This would tell you whether reporting the extreme option varied according to condition, and then you could look at the standardized residuals to see where a difference is happening. Or you could do pairwise tests with appropriate p-value adjustments. 

<br>

</details>

<!-- Plot First-Outcome Judgement -->

<details>
  <summary>
  Plot - Barplot of proportions
  </summary>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 7}
source('R Scripts/fo_recall_analysis.R')
plt_fo_prop
```

<br>

Note: 

- Proportions are taken within condition and context (high/low). E.g., All the green bars on the left side sum to 1, all the green bars on the right side sum to one, and so on. 
- The colour palette (which I don't anticipate you will like) is colourblind friendly.

<br>

</details>

<!--McNemar Test W/ Odds Ratio and Cohen's g effect size-->

<details>
  <summary>
  McNemar Test with odds ratio and Cohen's *g* effect sizes
  </summary>
  
  
<h3>McNemar Tests</h3>
```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(fo_stats, 'html') %>%
  kable_classic(full_width = T, html_font = "Arial")
```

<br>

<h4>Effect Size Interpretation</h4>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(interp, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

Note:

- Report either the odds ratio or Cohen's $g$, not both.
- Almost nobody has heard of Cohen's $g$ and wouldn't know how to interpret it. Furthermore, they would probably confuse it with Hedge's $g$ (which is a variant of Cohen's $d$).  Therefore, it's probably best to report the odds ratio.

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
chi <- round(fo_stats$Statistic, 2)
df <- round(fo_stats$df)
p <- round(fo_stats$p.value, 3)
OR <- round(fo_stats$OR, 2)
```

**Extreme First Condition:**

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(g1_tab, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

$\chi^2(`r df[1]`) = `r chi[1]`, p = `r p[1]`$

- There is no significant change in judgement evaluation between the high and low risky doors.

- The odds of getting the judgement correct given they are seeing the high-risk door is `r OR[1]` times that of seeing the low-risk door and getting it wrong.

<br>

**Extreme Last Condition:**

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(g2_tab, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

$\chi^2(`r df[2]`) = `r chi[2]`, p = `r p[2]`$

- There is a significant change in judgement evaluation between the high and low risky doors.

- The odds of getting the judgement correct given they are seeing the high-risk door is `r OR[2]` times that of seeing the low-risk door and getting it wrong.

<br>

**No Extreme Condition:**

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(g3_tab, 'html') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

$\chi^2(`r df[3]`) = `r chi[3]`, p = `r p[3]`$

- There is a significant change in judgement evaluation between the high and low risky doors.

- The odds of getting the judgement correct given they are seeing the high-risk door is `r OR[3]` times that of seeing the low-risk door and getting it wrong.

<br>

</details>

<!--3x2 Pearson Chi-Squared-->

<details>
  <summary>
  Alternative Analysis: 2x3 Chi-Squared Tests
  </summary>

```{r echo = FALSE, message = FALSE, warning = FALSE}
chi <- round(c(fo_high_test$statistic, fo_low_test$statistic), 2)
df <- round(c(fo_high_test$parameter, fo_low_test$parameter), 2)
p <- round(c(fo_high_test$p.value, fo_low_test$p.value), 3)
v <- round(c(fo_high_eff, fo_low_eff), 2)
```

<h3>High Value Results</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(fo_high_tab, 'html', caption = 'High Value Contingency Table') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

$\chi^2(`r df[1]`) = `r chi[1]`, p = `r p[1]`, \varphi_c = `r v[1]`$

- Cannot rule out that condition is independent of recalling the extreme value.


```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(std_res_high, 'html', caption = 'Standardized Residuals', digits = 2) %>%
  kable_classic(full_width = F, position = "float_left", html_font = "Arial")

kable(p_high, 'html', caption = 'p-values', digits = 3) %>%
  kable_classic(full_width = F, position = "float_left", html_font = "Arial")
```

<br>
<br>
<br>
<br>
<br>
<br>
<br>

Only the *Extreme 1st* condition differs significantly from the expected value. The *Extreme 1st* condition tends to not recall the extreme value.

- Extreme 1st: $z = `r round(std_res_high[4], 2)`, p = `r round(p_high[4], 3)`$

<br>
<br>

<h3>Low Value Results</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(fo_low_tab, 'html', caption = 'Low Value Contingency Table') %>%
  kable_classic(full_width = F, position = "left", html_font = "Arial")
```

<br>

$\chi^2(`r df[2]`) = `r chi[2]`, p = `r p[2]`, \varphi_c = `r v[2]`$

- Condition is not independent of recalling the extreme value; however, the association/effect is a weak/small one.


```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(std_res_low, 'html', caption = 'Standardized Residuals', digits = 2) %>%
  kable_classic(full_width = F, position = "float_left", html_font = "Arial")

kable(p_low, 'html', caption = 'p-values', digits = 3) %>%
  kable_classic(full_width = F, position = "float_left", html_font = "Arial")
```

<br>
<br>
<br>
<br>
<br>
<br>
<br>

The *Extreme 1st* and *No Extreme* conditions both differ significantly from the expected value. *Extreme 1st* tends to not recall the extreme value, whereas the *No Extreme* does.

- Extreme 1st: $z = `r round(std_res_low[4], 2)`, p = `r round(p_low[4], 3)`$

- No Extreme: $z = `r round(std_res_low[6], 2)`, p = `r round(p_low[6], 3)`$

<br>
<br>

**Note:**

- In the contingency tables, 'Yes' indicates the extreme value was recalled, 'No' indicates that it was not.

- $\varphi_c$ is Cramér’s V, a measure of association for two nominal variables (i.e., an effect size of sorts). It can take a value between 0 and 1, with 0 indicating no association (i.e., full independence). 

- Post-hoc analysis was conducted by evaluating the standardized residuals from the chi-square analysis because it seemed the most intuitive approach. However, another approach would be to conduct pairwise Pearson Chi-squared or Fisher Exact tests across the three conditions.


<br>

</details>

<br>

---

<br>

# **Frequency Judgement**

<details>
  <summary>
  Details and complications of frequency judgement results
  </summary>
  
It seems debatable whether the frequency judgement data should be plotted and analysed using means.  The data is almost certainly qualitative in nature.  For example, there is no reason to assume one person's judgment of 50% is the same as another person's. One person's 50% might be another's 70%. It's worth remembering **each participant is not providing a real frequency, they are giving their opinion about what the real frequency is.**

While the frequency judgement data has been plotted and analysed with means to remain consistent with the prior extreme-outcome work, there is a good argument that this data should be treated as nominal - similar to the first-outcome results (some might wonder why the two are being treated differently).  Admittedly, many (in Psychology) would probably argue this data is "sufficiently" quantitative given its wide sample space. Others might argue that it is qualitative, but ordinal (not nominal) and a Kruskal–Wallis test should be used. Do with this information what you will  ¯|_(ツ)_/¯
  
  <br>
  
  </details>

<details>
  <summary>
  Plot - Barplot of means
  </summary>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 7}
source('R Scripts/freq_judge_analysis.R')
plt_fj_means
```

<br>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(fj_bar_tab, 'html', digits = 3) %>%
  kable_classic(full_width = T, position = "center", html_font = "Arial")
```

<br>

</details>

<details>
  <summary>
  Plot - Violin plot
  </summary>
  
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 7}
plt_fj_violin
```

<br>

</details>

<details>
  <summary>
  2x3 ANOVA using linear mixed-effects models fit by maximum likelihood
  </summary>

<h3>ANOVA Table</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(aov_2x3[, -c(1)], 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

- base = intercept only (used as baseline and predicts overall mean ignoring other factors)
- cond_mod = effect of adding condition
- HL_mod = effect of adding context (i.e., High / Low choices)
- int_mod = interaction effect

<br>

<h3>Planned contrasts</h3>

```{r echo = FALSE, message = FALSE, warning = FALSE}
kable(round(pc, 3), 'html', digits = 3) %>%
  kable_classic(full_width = T, html_font = "Arial")
```

- E1_v_E2NE = *Extreme First* vs. combined effect of *Extreme Last* and *No Extreme*
- E2_v_NE = *Extreme Last* vs. *No Extreme*
- FJ_context1 = *High vs Low* (same test as row 3 in the ANOVA table)

<br>

<h3>Conclusions</h3> 

```{r echo = FALSE, message = FALSE, warning = FALSE}
df = aov_2x3$df[2:4] - aov_2x3$df[1:3]
chi = round(aov_2x3$L.Ratio[2:4], 2)
p = round(aov_2x3$`p-value`[2:4], 3)
R2 = round(aov_2x3$pseudo_R2[2:4], 2)
BF = format(round(aov_2x3$BF_10[2:4], 2), scientific = FALSE)

b = round(pc$Value[c(2, 3, 5, 6)], 3)
df_2 = round(pc$DF[c(2, 3, 5, 6)])
t = round(pc$`t-value`[c(2, 3, 5, 6)], 2)
p_2 = round(pc$`p-value`[c(2, 3, 5, 6)], 3)
r = round(pc$r_effect[c(2, 3, 5, 6)], 2)
```

**Main effect of of condition:**

$\chi^2 (`r df[1]`) = `r chi[1]`, p = `r p[1]`, R^2_N = `r R2[1]`, BF_{10} = `r BF[1]`$

- There is a small, but significant, main effect of condition on the frequency judgement of the risky doors. Note that the Bayes Factor suggests this isn't contributing any evidence.

<br>

**Main effect of of context (high vs low):**

$\chi^2 (`r df[2]`) = `r chi[2]`, p = `r p[2]`, R^2_N = `r R2[2]`, BF_{10} = `r BF[2]`$

- There is a main effect of context (high-value choices vs. low-value) on the frequency judgement of the risky doors. Bayes Factor results imply this is the only predictor of merit in the experiment.

<br>

**Interaction:**

$\chi^2 (`r df[3]`) = `r chi[3]`, p = `r p[3]`, R^2_N = `r R2[3]`, BF_{10} = `r BF[3]`$

- There is a small, but significant, interaction. The Bayes Factor suggests this isn't contributing any evidence.

<br>

**Planned comparisons:**

Extreme First vs. (Extreme Last & No Extreme)

$t(`r df_2[1]`) = `r t[1]`$, $p = `r p_2[1]`$, $r = `r r[1]`$

- The *Extreme First* condition is significantly different from the combination of the other two conditions. Note that the effect is small and may be of little practical value.

<br>

Extreme Last vs. No Extreme

$t(`r df_2[2]`) = `r t[2]`$, $p = `r p_2[2]`$, $r = `r r[2]`$

- The *Extreme Last* and *No Extreme* conditions do not significantly differ. 

<br>

Extreme First vs. (Extreme Last & No Extreme) | Context (i.e., High vs. Low)

$t(`r df_2[3]`) = `r t[3]`$, $p = `r p_2[3]`$, $r = `r r[3]`$

- The first planned comparison significantly differs depending on context (i.e., the Extreme First condition only differs from the other two conditions for the low-value choices). Note that the effect is small and may be of little practical value.

<br>

Extreme Last vs. No Extreme | Context (i.e., High vs. Low)

$t(`r df_2[4]`) = `r t[4]`$, $p = `r p_2[4]`$, $r = `r r[4]`$

- The second planned comparison does not significantly differ depending on context (i.e., no interaction with context).

<br>


**Note:** 

- $p = 0$ should be reported as $p < .001$

- $R^2_N$ is Nagelkerke's (also known as Cragg and Uhler's) pseudo $R^2$ [@Nagelkerke]. It isn't interpreted in exactly the same way as a $R^2$ based on ordinary least-squares regression, but it is bounded by 0 and 1 and higher values indicate a better model fit.

- Bayes Factors are reported as Inverse Bayes Factors, this means larger values
indicate greater support for the effect. Anything less than 1 should be considered as contributing no evidence. 

- If $BF_{10} > 150$, report that instead specifying the entire value.

</details>

<br>

---

<br>

# **R Citations**

`r R.version$version.string`

- nlme (`r packageVersion('nlme')`) [@nlme]
- patchwork (`r packageVersion('patchwork')`) [@patchwork]
- RColorBrewer (`r packageVersion('RColorBrewer')`) [@RColorBrewer]
- rcompanion (`r packageVersion('rcompanion')`) [@rcompanion]
- tidyverse (`r packageVersion('tidyverse')`) [@tidyverse]
- WRS2 (`r packageVersion('WRS2')`) [@WRS2]

<br>

---

<br>

# **References**


